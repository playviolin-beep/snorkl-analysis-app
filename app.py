import streamlit as st
import pandas as pd
import os
import glob
import google.generativeai as genai
import time
import altair as alt
import re

# ==========================================
# 1. ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
# ==========================================
st.set_page_config(page_title="Snorkl ë§ˆìŠ¤í„° (ìµœì¢…)", layout="wide")
st.title("ğŸ« Snorkl í•™ê¸‰ë³„ ì„¸íŠ¹ ê´€ë¦¬ ì‹œìŠ¤í…œ (ìµœì¢… ì™„ì„±íŒ)")

# í•„ìˆ˜ í´ë” ìƒì„±
for folder in ["data", "data/classes", "data/history", "data/questions"]:
    if not os.path.exists(folder): os.makedirs(folder)

def load_csv_safe(file_buffer):
    # CSV íŒŒì¼ ì•ˆì „ ë¡œë“œ
    try:
        return pd.read_csv(file_buffer, encoding='utf-8')
    except UnicodeDecodeError:
        file_buffer.seek(0)
        return pd.read_csv(file_buffer, encoding='cp949')
    except Exception: return None

def get_grade_char(score):
    # 4ì  ì²™ë„ ë³€í™˜
    try:
        s = float(score)
        if s >= 4: return "A"
        elif s >= 3: return "B"
        elif s >= 2: return "C"
        elif s >= 1: return "D"
        else: return "E"
    except: return "E"

# [ì •ë‹µ íŒë‹¨ ë¡œì§]
def check_is_correct(value):
    val_str = str(value).lower().strip()
    true_keywords = ['yes', 'true', 'pass', 'correct', 'right', 'o', 'ì •ë‹µ', 'ë§ìŒ', 'y', 't']
    
    if val_str in true_keywords: return 1
    for k in true_keywords:
        if val_str.startswith(k): return 1
    return 0

# [í•µì‹¬ ê¸°ëŠ¥] Snorkl ë°ì´í„° êµ¬ì¡° ë³€í™˜
def process_snorkl_data(df):
    long_data = []
    cols = df.columns
    prefix_map = {} 
    
    for c in cols:
        if "Response" in c and "Best" not in c:
            match = re.match(r"^(\d+)(st|nd|rd|th)", c)
            if match:
                order_num = int(match.group(1))
                prefix = match.group(0) 
                if prefix + " Response" in c:
                    prefix_map[order_num] = prefix + " Response"

    sorted_orders = sorted(prefix_map.keys())
    
    for idx, row in df.iterrows():
        f_name = str(row.get('First Name', '')).strip()
        l_name = str(row.get('Last Name', '')).strip()
        
        for order in sorted_orders:
            prefix = prefix_map[order]
            col_correct = next((c for c in cols if c.startswith(prefix) and ("Correct" in c or "Pass" in c)), None)
            col_score = next((c for c in cols if c.startswith(prefix) and "Score" in c), None)
            
            if col_correct and col_score:
                val_correct = row[col_correct]
                val_score = row[col_score]
                
                if str(val_correct).strip() in ['-', 'nan', '', 'None', 'NaT']: continue
                
                try: num_score = float(val_score)
                except: num_score = 0.0
                
                long_data.append({
                    'First Name': f_name,
                    'Last Name': l_name,
                    'Attempt_Order': order,
                    'Raw_Correct': str(val_correct),
                    'Numeric_Score': num_score,
                    'Is_Correct_Val': check_is_correct(val_correct)
                })
                
    return pd.DataFrame(long_data)

# [ë°ì´í„° ë¡œë“œ ë° ì»¬ëŸ¼ í‘œì¤€í™”]
def standardize_columns(df):
    if 'Q_Title' in df.columns:
        df.rename(columns={'Q_Title': 'Question_Title'}, inplace=True)
    return df

# ==========================================
# 2. ë°ì´í„° ë¡œë“œ
# ==========================================
RUBRIC_DB = {} 
rubric_path = os.path.join("data", "rubric.csv")
if os.path.exists(rubric_path):
    try:
        df_r = pd.read_csv(rubric_path)
        RUBRIC_DB = df_r.set_index('ì„±ì·¨ê¸°ì¤€').to_dict('index')
    except: pass

# ==========================================
# 3. ì‚¬ì´ë“œë°”
# ==========================================
with st.sidebar:
    st.header("ğŸ”§ ê´€ë¦¬ì ë©”ë‰´")
    api_key = st.text_input("Google AI Studio Key", type="password")
    
    st.divider()
    st.subheader("ğŸ“‚ ë°ì´í„° íŒŒì¼ ê´€ë¦¬")
    up_rubric = st.file_uploader("1. ì„±ì·¨ê¸°ì¤€ ë§¤í•‘ìš© (rubric.csv)", type='csv')
    if up_rubric:
        with open(rubric_path, "wb") as f: f.write(up_rubric.getbuffer())
        st.success("ì €ì¥ ì™„ë£Œ"); time.sleep(1); st.rerun()
    
    st.info(f"DB í˜„í™©: ì„±ì·¨ê¸°ì¤€ {len(RUBRIC_DB)}ê°œ")

    st.divider()
    st.subheader("ğŸ“‚ ìˆ˜ì—…(ë°˜) ë“±ë¡")
    new_class_name = st.text_input("ìˆ˜ì—…ëª… (ì˜ˆ: 1í•™ë…„7ë°˜)")
    roster_file = st.file_uploader("ëª…ë ¬í‘œ CSV", type=['csv'], key="roster")
    if st.button("ìˆ˜ì—… ë“±ë¡"):
        if new_class_name and roster_file:
            df = load_csv_safe(roster_file)
            if df is not None:
                df = df.astype(str)
                for c in df.columns: df[c] = df[c].str.strip()
                df.to_csv(os.path.join("data", "classes", f"roster_{new_class_name}.csv"), index=False, encoding='utf-8-sig')
                st.success("ë“±ë¡ ì™„ë£Œ")

    def get_class_list():
        files = glob.glob(os.path.join("data", "classes", "roster_*.csv"))
        return [os.path.basename(f).replace("roster_", "").replace(".csv", "") for f in files]

# ==========================================
# 4. ë©”ì¸ í™”ë©´
# ==========================================
class_list = get_class_list()

if not class_list:
    st.warning("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìˆ˜ì—…ì„ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”.")
else:
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ 1. ë¬¸í•­ ë“±ë¡", "ğŸ“¤ 2. ê²°ê³¼ ëˆ„ì ", "ğŸ§ 3. íŒ©íŠ¸ ì¶”ì¶œ", "ğŸ“Š 4. í†µê³„ ëŒ€ì‹œë³´ë“œ"])

    # [íƒ­ 1] ë¬¸í•­ ë“±ë¡ (ë²„ê·¸ ìˆ˜ì •ë¨)
    with tab1:
        st.subheader("ğŸ“Œ ë¬¸í•­ ë“±ë¡ (AI ë¶„ì„ì˜ ê¸°ì¤€)")
        c1, c2 = st.columns([2, 1])
        with c1:
            q_title = st.text_input("ë¬¸í•­ ì œëª©", placeholder="ì˜ˆ: 1-1-1. ë¬¸ì œ1")
            q_prompt = st.text_area("ë¬¸í•­ ì§€ë¬¸ (êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”!)")
            q_answer = st.text_area("ì •ë‹µ/í‰ê°€ìš”ì†Œ (AIê°€ ì°¸ê³ í•  í•µì‹¬ í¬ì¸íŠ¸)")
        with c2:
            st.markdown("**ì„±ì·¨ê¸°ì¤€ ë§¤í•‘**")
            std_opts = list(RUBRIC_DB.keys()) if RUBRIC_DB else ["ë°ì´í„° ì—†ìŒ"]
            
            # [ë²„ê·¸ ìˆ˜ì •] Session Stateë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ íƒ ì¸ë±ìŠ¤ ê´€ë¦¬
            if 'std_select_index' not in st.session_state:
                st.session_state['std_select_index'] = 0

            if st.button("ğŸ¤– AI ë§¤í•‘ ì¶”ì²œ"):
                if not api_key: st.error("API í‚¤ í•„ìš”")
                else:
                    try:
                        genai.configure(api_key=api_key)
                        model = genai.GenerativeModel('gemini-2.0-flash')
                        res = model.generate_content(f"ë¬¸ì œ: {q_prompt}\nì •ë‹µ: {q_answer}\n\në‹¤ìŒ ì¤‘ ê°€ì¥ ì ì ˆí•œ ì„±ì·¨ê¸°ì¤€ í•˜ë‚˜ë¥¼ ê³¨ë¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´:\n{chr(10).join(std_opts)}")
                        rec_std = res.text.strip()
                        
                        if rec_std in std_opts:
                            # ì¶”ì²œëœ ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ Session State ì—…ë°ì´íŠ¸
                            new_index = std_opts.index(rec_std)
                            st.session_state['std_select_index'] = new_index
                            st.success(f"ì¶”ì²œ ì™„ë£Œ: {rec_std}")
                            time.sleep(0.5)
                            st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë“œë¡­ë‹¤ìš´ ë³€ê²½ ì ìš©
                        else:
                            st.warning(f"ì¶”ì²œëœ ê°’({rec_std})ì´ ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤.")
                    except: pass
            
            # index íŒŒë¼ë¯¸í„°ì— Session State ì—°ê²°
            q_std = st.selectbox("ì„±ì·¨ê¸°ì¤€ ì„ íƒ", std_opts, index=st.session_state['std_select_index'])
            
            if st.button("ë¬¸í•­ ì €ì¥"):
                if q_title:
                    new_df = pd.DataFrame([{"Title": q_title, "Prompt": q_prompt, "Answer": q_answer, "Standard": q_std}])
                    p = "data/questions_db.csv"
                    new_df.to_csv(p, mode='a', header=not os.path.exists(p), index=False, encoding='utf-8-sig')
                    st.success("ì €ì¥ ì™„ë£Œ")

    # [íƒ­ 2] ê²°ê³¼ ëˆ„ì 
    with tab2:
        st.subheader("ğŸ“¥ Snorkl ê²°ê³¼ ì—…ë¡œë“œ")
        c1, c2 = st.columns(2)
        target_class = c1.selectbox("ìˆ˜ì—… ì„ íƒ", class_list)
        q_list = []
        if os.path.exists("data/questions_db.csv"):
            q_list = pd.read_csv("data/questions_db.csv")['Title'].tolist()
        sel_q = c2.selectbox("ë¬¸í•­ ì„ íƒ", q_list)
        
        up_res = st.file_uploader("Snorkl CSV ì—…ë¡œë“œ", type='csv')
        
        if up_res and st.button("ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥"):
            df_res = load_csv_safe(up_res)
            if df_res is not None:
                long_df = process_snorkl_data(df_res)
                if long_df.empty:
                    st.error("ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: ìœ íš¨í•œ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    df_cls = pd.read_csv(os.path.join("data", "classes", f"roster_{target_class}.csv"))
                    df_cls = df_cls.astype(str)
                    for c in df_cls.columns: df_cls[c] = df_cls[c].str.strip()
                    
                    long_df['First Name'] = long_df['First Name'].astype(str).str.strip()
                    long_df['Last Name'] = long_df['Last Name'].astype(str).str.strip()
                    
                    merged = pd.merge(df_cls, long_df, on=['First Name', 'Last Name'], how='left')
                    merged['Question_Title'] = sel_q
                    
                    ts = int(time.time())
                    path = os.path.join("data", "history", f"{target_class}_{ts}.csv")
                    merged.to_csv(path, index=False, encoding='utf-8-sig')
                    with open(path.replace(".csv", "_meta.txt"), "w") as f: f.write(sel_q)
                    
                    st.success(f"ì €ì¥ ì™„ë£Œ ({len(merged)}í–‰)")

    # [íƒ­ 3] íŒ©íŠ¸ ì¶”ì¶œ
    with tab3:
        st.subheader("ğŸ§ ë°ì´í„° ê¸°ë°˜ ì—­ëŸ‰ íŒ©íŠ¸ ì¶”ì¶œ")
        t_cls = st.selectbox("ë¶„ì„ ëŒ€ìƒ ë°˜", class_list, key="final")
        
        if st.button("ë°ì´í„° ë¡œë“œ & ë¶„ì„ ì¤€ë¹„"):
            files = glob.glob(os.path.join("data", "history", f"{t_cls}_*.csv"))
            if not files: st.warning("ë°ì´í„° ì—†ìŒ")
            else:
                full_df = pd.DataFrame()
                q_db = pd.read_csv("data/questions_db.csv")
                for fp in files:
                    try:
                        tmp = pd.read_csv(fp)
                        tmp = standardize_columns(tmp)
                        if 'Numeric_Score' not in tmp.columns:
                            tmp = process_snorkl_data(tmp)
                            tmp = standardize_columns(tmp)
                        
                        meta = fp.replace(".csv", "_meta.txt")
                        q_t = ""
                        if os.path.exists(meta):
                            with open(meta) as f: q_t = f.read().strip()
                            tmp['Question_Title'] = q_t
                        
                        if not tmp.empty and q_t:
                            qi = q_db[q_db['Title'] == q_t]
                            if not qi.empty:
                                tmp['Standard'] = qi.iloc[0]['Standard']
                                tmp['Prompt'] = qi.iloc[0]['Prompt']
                                tmp['Answer'] = qi.iloc[0]['Answer']
                            else:
                                tmp['Standard'] = "ë¯¸ë“±ë¡ ì„±ì·¨ê¸°ì¤€"
                                tmp['Prompt'] = "ì •ë³´ ì—†ìŒ"
                                tmp['Answer'] = "ì •ë³´ ì—†ìŒ"
                        full_df = pd.concat([full_df, tmp])
                    except: pass
                
                if 'Numeric_Score' in full_df.columns:
                    full_df = full_df.dropna(subset=['Numeric_Score'])
                    st.session_state['grouped'] = full_df.groupby(['First Name', 'Last Name'])
                    st.session_state['total_db_questions'] = len(q_db)
                    st.success(f"ë¡œë“œ ì™„ë£Œ (ì´ {len(full_df)}ê±´ ì‹œë„)")
                else: st.error("ìœ íš¨ ë°ì´í„° ì—†ìŒ")

        if 'grouped' in st.session_state and st.button("ğŸš€ íŒ©íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"):
            if not api_key: st.error("API í‚¤ í•„ìš”")
            else:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-2.0-flash')
                results = []
                bar = st.progress(0)
                students = list(st.session_state['grouped'])
                total_db_q = st.session_state.get('total_db_questions', 0)
                
                for idx, ((fname, lname), s_df) in enumerate(students):
                    # ì •ëŸ‰ì  ë°ì´í„° ê³„ì‚°
                    attempted_q_count = s_df['Question_Title'].nunique()
                    solved_q_count = s_df.groupby('Question_Title')['Is_Correct_Val'].max().sum()
                    perfect_score_count = s_df[s_df['Numeric_Score'] >= 4.0]['Question_Title'].nunique()
                    
                    stats_text = f"""
                    [ì •ëŸ‰ì  ì„±ì·¨ ë°ì´í„°]
                    - ì „ì²´ ë¬¸í•­ ìˆ˜(DB ê¸°ì¤€): {total_db_q}ê°œ
                    - ì‹œë„í•œ ë¬¸í•­ ìˆ˜: {attempted_q_count}ê°œ
                    - í•´ê²°(ì •ë‹µ) ë¬¸í•­ ìˆ˜: {solved_q_count}ê°œ
                    - ë§Œì (4.0) ë‹¬ì„± ë¬¸í•­ ìˆ˜: {perfect_score_count}ê°œ
                    """
                    
                    analysis_data = ""
                    if 'Standard' in s_df.columns:
                        for std, grp in s_df.groupby('Standard'):
                            analysis_data += f"\n=== [ì„±ì·¨ê¸°ì¤€] {std} ===\n"
                            q_grp = grp.groupby('Question_Title')
                            for qt, q_sub in q_grp:
                                q_sub = q_sub.sort_values('Attempt_Order')
                                attempts = len(q_sub)
                                scores = q_sub['Numeric_Score'].tolist()
                                has_success = 1 in q_sub['Is_Correct_Val'].tolist()
                                start, end = scores[0], scores[-1]
                                
                                p_txt = str(q_sub.iloc[0].get('Prompt', ''))
                                a_txt = str(q_sub.iloc[0].get('Answer', ''))
                                
                                analysis_data += f"""
                                - ë¬¸í•­: {qt}
                                - ë¬¸ì œ ë‚´ìš©: {p_txt}
                                - í‰ê°€ í•µì‹¬: {a_txt}
                                - ì´ë ¥: {attempts}íšŒ ì‹œë„ ({start} -> {end})
                                - ê²°ê³¼: {'ì„±ê³µ(Yes)' if has_success else 'ì‹¤íŒ¨(No)'}
                                """
                    
                    prompt = f"""
                    ë‹¹ì‹ ì€ ëƒ‰ì² í•œ êµìœ¡ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. í•™ìƒ ë°ì´í„°ë¥¼ ë³´ê³  ì •ëŸ‰ì  í†µê³„ì™€ ì§ˆì  íŒ©íŠ¸ë¥¼ ìš”ì•½í•˜ì„¸ìš”.

                    [ì…ë ¥ ë°ì´í„°]
                    {stats_text}
                    {analysis_data}

                    [ì‘ì„± ì›ì¹™]
                    1. **ì •ëŸ‰ ë°ì´í„° í•„ìˆ˜**: [ì¢…í•© ìš”ì•½]ì— ìœ„ í†µê³„ ìˆ˜ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ì ì„ ê²ƒ.
                    2. **ì¼ê´€ëœ í¬ë§·**: ëª¨ë“  í•™ìƒì—ê²Œ ë™ì¼í•œ í˜•ì‹ ì ìš©.
                    3. **íŒ©íŠ¸ ì¤‘ì‹¬**: ë¯¸ì‚¬ì—¬êµ¬ ì œì™¸, ê±´ì¡°í•œ ì„œìˆ .

                    [ì¶œë ¥ í¬ë§· ì˜ˆì‹œ]
                    [ì¢…í•© ìš”ì•½]
                    - ì „ì²´ ë¬¸í•­: (ìˆ«ì)ê°œ / ì‹œë„: (ìˆ«ì)ê°œ / í•´ê²°: (ìˆ«ì)ê°œ / ë§Œì : (ìˆ«ì)ê°œ

                    [ì„±ì·¨ê¸°ì¤€: (ì„±ì·¨ê¸°ì¤€ëª…)]
                    1. (ë¬¸í•­ëª…)
                       - ë‚´ìš©: (ë¬¸ì œ í•µì‹¬ ìš”ì•½)
                       - ê²°ê³¼: (N)íšŒ ì‹œë„ í›„ (ì„±ê³µ/ì‹¤íŒ¨), ì ìˆ˜ ë³€í™”((ì‹œì‘)->(ë))
                       - ì—­ëŸ‰: (í‰ê°€ í•µì‹¬ì— ê¸°ë°˜í•œ ì—­ëŸ‰ íŒ©íŠ¸)
                    
                    (ë°˜ë³µ)
                    """
                    try:
                        time.sleep(0.5)
                        res = model.generate_content(prompt)
                        out = res.text.strip()
                    except: out = "ì‹¤íŒ¨"
                    
                    results.append({
                        "í•™ë²ˆ": lname, "ì´ë¦„": fname,
                        "ì „ì²´_ë¬¸í•­": total_db_q, "ì‹œë„": attempted_q_count,
                        "í•´ê²°": solved_q_count, "ë§Œì ": perfect_score_count,
                        "ë¦¬í¬íŠ¸": out
                    })
                    bar.progress((idx+1)/len(students))
                
                res_df = pd.DataFrame(results)
                st.dataframe(res_df)
                st.download_button("ğŸ’¾ íŒ©íŠ¸ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", res_df.to_csv(index=False, encoding='utf-8-sig'), "íŒ©íŠ¸_ë¦¬í¬íŠ¸.csv")

    # [íƒ­ 4] ëŒ€ì‹œë³´ë“œ
    with tab4:
        st.subheader("ğŸ“Š ì¢…í•© í†µê³„ ëŒ€ì‹œë³´ë“œ")
        all_files = glob.glob(os.path.join("data", "history", "*.csv"))
        if all_files:
            df_list = []
            for f in all_files:
                try: 
                    t = pd.read_csv(f)
                    t = standardize_columns(t)
                    if 'Numeric_Score' not in t.columns:
                        t = process_snorkl_data(t)
                        t = standardize_columns(t)
                    meta = f.replace(".csv", "_meta.txt")
                    if os.path.exists(meta):
                        with open(meta) as f2: t['Question_Title'] = f2.read().strip()
                    df_list.append(t)
                except: pass
            
            if df_list:
                df_all = pd.concat(df_list, ignore_index=True)
                if 'Numeric_Score' in df_all.columns:
                    df_valid = df_all.dropna(subset=['Numeric_Score'])
                    if not df_valid.empty:
                        q_solved = df_valid.groupby(['Last Name', 'First Name', 'Question_Title'])['Is_Correct_Val'].max()
                        solve_rate = q_solved.mean() * 100
                        
                        m1, m2, m3 = st.columns(3)
                        m1.metric("ì´ ëˆ„ì  ì‹œë„", f"{len(df_valid)}íšŒ")
                        m2.metric("ë¬¸í•­ í•´ê²°ë¥ ", f"{solve_rate:.1f}%")
                        m3.metric("í‰ê·  ì ìˆ˜", f"{df_valid['Numeric_Score'].mean():.2f}")
                        
                        st.divider()
                        st.markdown("### ğŸ“‰ ê°œì¸ë³„ ì´ë ¥")
                        df_valid['Key'] = df_valid['Last Name'].astype(str) + " " + df_valid['First Name'].astype(str)
                        sel = st.selectbox("í•™ìƒ ì„ íƒ", df_valid['Key'].unique())
                        if sel:
                            s_data = df_valid[df_valid['Key'] == sel].copy().sort_values('Attempt_Order')
                            s_data['Seq'] = range(1, len(s_data)+1)
                            c1, c2 = st.columns(2)
                            with c1:
                                st.altair_chart(alt.Chart(s_data).mark_line(point=True).encode(
                                    x=alt.X('Seq:O', title='ìˆœì„œ'), y='Numeric_Score', color='Question_Title', tooltip=['Question_Title', 'Numeric_Score']
                                ), use_container_width=True)
                            with c2:
                                st.altair_chart(alt.Chart(s_data).mark_circle(size=100).encode(
                                    x=alt.X('Seq:O', title='ìˆœì„œ'), y='Is_Correct_Val', color='Is_Correct_Val', tooltip=['Question_Title', 'Is_Correct_Val']
                                ), use_container_width=True)
                else: st.info("ìœ íš¨ ë°ì´í„° ì—†ìŒ")
        else: st.info("ë°ì´í„° íŒŒì¼ ì—†ìŒ")